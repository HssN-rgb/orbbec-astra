def camera_mapping_loop(self):
        try:
            # Initialize OpenNI2 with the correct path
            try:
                openni2.initialize(r'C:\Users\dell laptop\vscod\OpenNI_2.3.0.86_202210111950_4c8f5aa4_beta6_windows\Win64-Release\sdk\libs')
                print("OpenNI2 initialized successfully!")
            except Exception as e:
                print(f"Error initializing OpenNI2: {e}")
                return

            # Open device and streams
            try:
                dev = openni2.Device.open_any()
                print("Device opened successfully!")

                depth_stream = dev.create_depth_stream()
                depth_stream.start()
                print("Depth stream started successfully!")

                color_stream = dev.create_color_stream()
                color_stream.start()
                print("Color stream started successfully!")
            except Exception as e:
                print(f"Failed to initialize streams: {e}")
                openni2.unload()
                return

            # Initialize MediaPipe for body pose tracking instead of hand tracking
            mp_pose = mp.solutions.pose
            pose = mp_pose.Pose(min_detection_confidence=0.7, min_tracking_confidence=0.7)
            mp_drawing = mp.solutions.drawing_utils

            # OpenCV window for square mapping
            cv2.namedWindow("Camera Feed")
            cv2.setMouseCallback("Camera Feed", self.draw_3d_square)

            # Store the latest depth array for use in mouse callback
            self.latest_depth_array = None

            while self.mapping_active:
                # Capture frames
                color_frame = color_stream.read_frame()
                color_data = color_frame.get_buffer_as_uint8()
                color_image = np.frombuffer(color_data, dtype=np.uint8)
                color_image.shape = (color_frame.height, color_frame.width, 3)
                color_image = cv2.cvtColor(color_image, cv2.COLOR_RGB2BGR)

                # Get depth frame
                depth_frame = depth_stream.read_frame()
                depth_data = depth_frame.get_buffer_as_uint16()
                depth_array = np.frombuffer(depth_data, dtype=np.uint16)
                depth_array.shape = (depth_frame.height, depth_frame.width)
                
                # Store the latest depth array for the callback
                self.latest_depth_array = depth_array

                # Draw the 3D square and grid on the camera feed
                # Create a transparent overlay for the grid
                overlay = color_image.copy()

                # Draw the 3D square and grid on the overlay (not directly on the main image)
                overlay = self.draw_3d_square_on_image(overlay)

                # Blend the overlay with the original image (alpha controls transparency)
                alpha = 0.4  # Adjust this to make the grid more/less transparent
                color_image = cv2.addWeighted(overlay, alpha, color_image, 1 - alpha, 0)

                # Body pose tracking
                rgb_frame = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)
                results = pose.process(rgb_frame)

                # Track body pose
                if results.pose_landmarks:
                    # Draw the pose landmarks on top of everything else
                    mp_drawing.draw_landmarks(color_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)

                    # Get both wrist landmarks - 19:left wrist, 20:right wrist
                    landmarks = results.pose_landmarks.landmark
                    right_wrist = landmarks[20]  # Right wrist for cursor control
                    left_wrist = landmarks[19]   # Left wrist for depth comparison
                    
                    # Only proceed if right wrist has good visibility
                    if right_wrist.visibility > 0.5:
                        # Get coordinates of right wrist for cursor position
                        hand_x = int(right_wrist.x * color_frame.width)
                        hand_y = int(right_wrist.y * color_frame.height)
                        
                        # Label the wrists
                        cv2.putText(color_image, "R", (hand_x+5, hand_y+5), 
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                        
                        if left_wrist.visibility > 0.5:
                            left_x = int(left_wrist.x * color_frame.width)
                            left_y = int(left_wrist.y * color_frame.height)
                            cv2.putText(color_image, "L", (left_x+5, left_y+5), 
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

                        # Check if wrist is within valid depth range
                        if 0 <= hand_x < depth_array.shape[1] and 0 <= hand_y < depth_array.shape[0]:
                            depth_value = depth_array[hand_y, hand_x]
                            if np.isfinite(depth_value):
                                print(f"Raw RIGHT wrist depth: {int(depth_value)}mm")
                            else:
                                print("Raw RIGHT wrist depth: infinite (unable to determine)")

                            # Only process wrist within the configured distance range
                            if depth_value > 0 and self.min_hand_distance <= depth_value <= self.max_hand_distance:
                                # Highlight the wrist tracking point
                                cv2.circle(color_image, (hand_x, hand_y), 7, (0, 255, 0), -1)
                                
                                # Create 3D point (x, y, z)
                                point_3d = (hand_x, hand_y, depth_value)
                                
                                # Calculate distance to wall
                                distance_to_wall = self.distance_to_wall(point_3d)
                                print(f"Distance to camera: {int(depth_value)}mm")

                                # Check if distance is finite
                                if np.isfinite(distance_to_wall):
                                    print(f"Distance to wall: {int(distance_to_wall)}mm")
                                else:
                                    print("Distance to wall: infinite (unable to determine)")
                                
                                # Check if wrist is inside the projected 3D square
                                is_inside, mapped_pos = self.check_point_in_3d_square((hand_x, hand_y, depth_value))
                                
                                if is_inside:
                                    # Map wrist position to screen coordinates
                                    screen_x, screen_y = mapped_pos
                                    
                                    # Move cursor
                                    pyautogui.moveTo(screen_x, screen_y)
                                    
                                    # Check if left wrist is also visible
                                    if left_wrist.visibility > 0.5 and 0 <= left_x < depth_array.shape[1] and 0 <= left_y < depth_array.shape[0]:
                                        # Get left wrist depth
                                        left_depth = depth_array[left_y, left_x]
                                        
                                        if left_depth > 0:
                                            # Compare left and right wrist depths
                                            print(f"Left wrist depth: {int(left_depth)}mm, Right wrist depth: {int(depth_value)}mm")
                                            
                                            # NEW LOGIC: Find the closest grid point to the hand position
                                            should_click = False  # Default to no click
                                            
                                            # Only proceed with grid-based click detection if we have grid points defined
                                            if len(self.grid_points_3d) > 0:
                                                # Find the nearest grid point to the current hand position
                                                nearest_grid_point = None
                                                nearest_distance = float('inf')
                                                
                                                for grid_point in self.grid_points_3d:
                                                    grid_x, grid_y, grid_depth = grid_point
                                                    
                                                    # Calculate 2D Euclidean distance to the grid point
                                                    distance = ((grid_x - hand_x)**2 + (grid_y - hand_y)**2)**0.5
                                                    
                                                    # Update nearest point if this one is closer
                                                    if distance < nearest_distance:
                                                        nearest_distance = distance
                                                        nearest_grid_point = grid_point
                                                
                                                # If we found a nearby grid point (should always be true if grid exists)
                                                if nearest_grid_point:
                                                    nearest_x, nearest_y, nearest_depth = nearest_grid_point
                                                    
                                                    # Visual feedback - draw line connecting hand to nearest grid point
                                                    cv2.line(color_image, (hand_x, hand_y), (int(nearest_x), int(nearest_y)), 
                                                            (255, 0, 255), 2)
                                                    cv2.circle(color_image, (int(nearest_x), int(nearest_y)), 5, 
                                                            (255, 0, 255), -1)
                                                    
                                                    # Show the nearest grid point depth
                                                    grid_info = f"Nearest grid: {int(nearest_depth)}mm, Hand: {int(depth_value)}mm"
                                                    cv2.putText(color_image, grid_info, 
                                                            (hand_x + 10, hand_y + 50), cv2.FONT_HERSHEY_SIMPLEX, 
                                                            0.5, (255, 0, 255), 1, cv2.LINE_AA)
                                                    
                                                    # Calculate depth difference
                                                    depth_diff = depth_value - nearest_depth
                                                    cv2.putText(color_image, f"Depth diff: {int(depth_diff)}mm", 
                                                            (hand_x + 10, hand_y + 70), cv2.FONT_HERSHEY_SIMPLEX, 
                                                            0.5, (255, 0, 255), 1, cv2.LINE_AA)
                                                    
                                                    # Define threshold for click trigger (negative means hand is closer than grid)
                                                    click_threshold = -20  # mm - adjust based on testing
                                                    
                                                    # Trigger click when hand is closer to camera than grid point by threshold amount
                                                    should_click = depth_diff <= click_threshold
                                                    
                                                    # Visual feedback for click proximity
                                                    proximity_percentage = min(1.0, max(0.0, abs(depth_diff / click_threshold)))
                                                    proximity_color = (0, int(255 * (1-proximity_percentage)), int(255 * proximity_percentage))
                                                    
                                                    # Circle changes from green to red as you get closer to clicking
                                                    cv2.circle(color_image, (hand_x, hand_y), 15, proximity_color, 2)
                                                    
                                                    # Additional feedback text
                                                    proximity_text = f"Click proximity: {int(proximity_percentage * 100)}%"
                                                    cv2.putText(color_image, proximity_text, 
                                                            (hand_x + 10, hand_y + 90), cv2.FONT_HERSHEY_SIMPLEX, 
                                                            0.5, proximity_color, 1, cv2.LINE_AA)
                                            else:
                                                # No grid points yet - show warning
                                                cv2.putText(color_image, "Define 3D grid for click detection", 
                                                        (20, 240), cv2.FONT_HERSHEY_SIMPLEX, 
                                                        0.7, (0, 0, 255), 2, cv2.LINE_AA)
                                            
                                            # Handle touch/click action
                                            if should_click:
                                                touch_pos = (int(screen_x-self.start_x), int(screen_y-self.start_y))
                                                
                                                # If in drawing mode, add point to drawing
                                                if self.drawing_mode:
                                                    self.add_drawing_point(touch_pos)
                                                    print(f"Drawing at {touch_pos}")
                                                    
                                                    # Visual feedback for drawing
                                                    cv2.circle(color_image, (hand_x, hand_y), 20, self.drawing_color, -1)
                                                else:
                                                    # Standard click behavior
                                                    print(f"Click at {touch_pos} - nearby grid point triggered")
                                                    pyautogui.click(screen_x, screen_y)
                                                    
                                                    # Strong visual feedback for touch
                                                    cv2.circle(color_image, (hand_x, hand_y), 20, (0, 0, 255), -1)
                                                
                                                # Update touch state - for drawing continuation
                                                self.is_touching = True
                                            else:
                                                # Reset touch state when not clicking
                                                if self.is_touching:
                                                    self.is_touching = False
                                                    if self.drawing_mode:
                                                        # End current line
                                                        self.last_point = None
                                    else:
                                        # Only right wrist is visible
                                        cv2.putText(color_image, "Left wrist not detected", 
                                                (20, 210), cv2.FONT_HERSHEY_SIMPLEX, 
                                                0.7, (0, 0, 255), 2, cv2.LINE_AA)
                                else:
                                    # Wrist is inside detection range but outside mapped screen area
                                    cv2.putText(color_image, "Wrist outside mapped area", 
                                            (hand_x + 10, hand_y - 10),
                                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1, cv2.LINE_AA)
                        else:
                            print("the hand is outside valid depth range")
                # Show settings information
                cv2.putText(color_image, f"Click depth threshold: {self.grid_depth_threshold}mm", 
                        (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2, cv2.LINE_AA)
                
                cv2.putText(color_image, f"Hand range: {self.min_hand_distance}-{self.max_hand_distance}mm", 
                        (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)
                
                # Display body tracking status
                if self.use_body_tracking:
                    cv2.putText(color_image, "BODY TRACKING: ON", 
                            (color_image.shape[1] - 250, 60), cv2.FONT_HERSHEY_SIMPLEX, 
                            0.7, (0, 255, 0), 2, cv2.LINE_AA)
                    cv2.putText(color_image, f"Body click threshold: {self.body_click_threshold}mm",
                            (20, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)
                
                # Display drawing mode status                    
                if len(self.square_points_3d) < 4:
                    cv2.putText(color_image, f"Click to define 3D square: {len(self.square_points_3d)}/4 points", 
                            (20, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)
                else:
                    cv2.putText(color_image, "3D square mapped! Move wrists inside square.", 
                            (20, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)
                    cv2.putText(color_image, f"Grid resolution: {self.grid_resolution}x{self.grid_resolution}", 
                            (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)
                    
                    # Display depth mode
                    modes = ["All Points", "Alternate Points", "Minimal"]
                    cv2.putText(color_image, f"Depth mode: {modes[self.depth_display_mode]}", 
                            (20, 180), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)

                cv2.imshow("Camera Feed", color_image)
                
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('r'):  # Reset square points
                    self.square_points_2d = []
                    self.square_points_3d = []
                    self.grid_points_2d = []
                    self.grid_points_3d = []
                    self.homography_matrix = None
                elif key == ord('g'):  # Toggle grid display
                    self.toggle_grid()
                elif key == ord('d'):  # Toggle depth display
                    self.toggle_depth()
                elif key == ord('m'):  # Cycle depth display mode
                    self.cycle_depth_mode()
                elif key == ord('+') or key == ord('='):  # Increase grid resolution
                    self.grid_resolution = min(10, self.grid_resolution + 1)
                    self.grid_slider.set(self.grid_resolution)
                    self.calculate_grid_points()
                elif key == ord('-'):  # Decrease grid resolution
                    self.grid_resolution = max(2, self.grid_resolution - 1)
                    self.grid_slider.set(self.grid_resolution)
                    self.calculate_grid_points()
                elif key == ord('['):  # Decrease grid depth threshold
                    self.grid_depth_threshold = max(5, self.grid_depth_threshold - 5)
                    self.grid_threshold_slider.set(self.grid_depth_threshold)
                elif key == ord(']'):  # Increase grid depth threshold
                    self.grid_depth_threshold = min(100, self.grid_depth_threshold + 5)
                    self.grid_threshold_slider.set(self.grid_depth_threshold)
                elif key == ord('p'):  # Toggle drawing mode
                    self.toggle_drawing_mode()
                elif key == ord('c'):  # Clear drawing
                    self.clear_drawing()
                elif key == ord('s'):  # Save drawing
                    self.save_drawing()
                elif key == ord('t'):  # Toggle grid-based depth mode
                    self.toggle_grid_depth()
                elif key == ord('b'):  # Toggle debug mode
                    self.toggle_debug_mode()
                elif key == ord('v'):  # Toggle body tracking
                    self.toggle_body_tracking()

                if len(self.grid_points_3d) == (self.grid_resolution + 1) * (self.grid_resolution + 1):
                    self.update_grid_window(depth_array)

            # Cleanup
            depth_stream.stop()
            color_stream.stop()
            openni2.unload()
            pose.close()
            cv2.destroyAllWindows()
        except Exception as e:
            print(f"Error during square mapping: {e}")
            import traceback
            traceback.print_exc()
